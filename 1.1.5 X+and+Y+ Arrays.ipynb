{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.1.5 X+and+Y+ Arrays.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNI+V/o8yl3ghaytAVmbNyb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jcEXeJny9C8i"},"source":["# Lecture Notes"]},{"cell_type":"markdown","metadata":{"id":"x3N6XEwx9Iv_"},"source":["<h2>Text Classification</h2>\r\n","\r\n","**Humans decide what categories to use for text classification, then we train AI to do the labelling.**\r\n","\r\n","The first kind of model that we’ll talk about is **text classification**. This fills one of the core slots in a pipeline, between data collection and visualization. We start by deciding what categories are important to us. This means that we create a complete classification system, in which each text belongs to one or another category. If I want to sort tweets by language, I first come up with examples of all the languages I am interested in. Some categories might be quite large (a majority class, like English) while others are quite small (a minority class, like Samoan).\r\n","\r\n","Then we train a classifier to automate the labelling task. Labelling here means assigning each text to the correct category. If a tweet is written in Samoan, I want the classifier to label it as Samoan. The goal, of course, is to automate labelling so that we can know the categories of millions or billions of texts. Training here means that we show the classifier examples with their correct labels until the machine is able to make accurate predictions on its own.\r\n","\r\n","Let’s break down the problem of text classification.\r\n","\r\n","\r\n","\r\n","1.  We need to design a category system. If I want to sort hotels by the kind of guests they cater to, I need to make up a set of hotel types: luxury vs. business vs. family vs. budget.\r\n","\r\n","2.  we need to represent language to focus on a particular kind of meaning. If I’m categorizing hotels, I want to focus on the topics that reviewers talk about: service, sleep quality, cleanliness, amenities. I need to make sure that the classifier captures these domains.\r\n","\r\n","3. We need to train and evaluate a classification model. This means I take hotel reviews from each category, show them to the classifier, and help it learn to distinguish between types of hotels. Then I test the classifier on examples it hasn’t seen before. How many does it get right?\r\n","\r\n","4. We’ll talk about how to annotate new datasets while ensuring that our labels are consistent. If we can’t agree, as humans, about what kinds of hotels there are, then we can’t teach a machine to do it for us.\r\n","\r\n","* Kinds of Categories. We can design categories that are based either on a: **document’s content, or its sentiment or its author**. Content is the meaning of the text, what it talks about: sports or politics or a new television show. Sentiment is the tone or emotional content of the text. For example, we could have an angry article about a rugby match and a joyous article; sometimes we need to know which is which. An author is the person who wrote the text: a middle-age American woman or a young Japanese man, for example. All this information, content and sentiment and author, are present in language. But they are contained in different parts of the text. We’ll explore how to represent language so that we focus on one or the other.\r\n","\r\n","* Supervised Learning. At its core, we as humans define this problem by deciding in advance what the categories will be. Some category systems are scientifically valid: for example, we know that we can identify the dialect or native language of a document’s author. But other category systems are not valid: for example, we can’t know what social clubs the author belongs to or what their favorite food is. We must establish a good justification for the categories we propose."]},{"cell_type":"markdown","metadata":{"id":"oxUCvdLg9Dcp"},"source":["# Colab Setup"]},{"cell_type":"code","metadata":{"id":"Sb6uzL9u9SPu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615924955665,"user_tz":240,"elapsed":32194,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"07e0d736-347f-45f2-a1c4-47c128687860"},"source":["# if you are running these labs in CoLab, you will first need to mount the drive and \r\n","# copy text_analitics.py to path \r\n","\r\n","from google.colab import drive\r\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1QfUtbEV9Si9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615924959296,"user_tz":240,"elapsed":1211,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"a666eae4-8bee-4401-c7fa-fad61ec65841"},"source":["###Add text_analytics.py to path \r\n","!cp \"/content/drive/My Drive/Colab Notebooks/CourseWork/Text Analytics and Natural Language Processing/text_analytics.py\" .\r\n","print(\"Done!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jzMC7zDN9Dxo"},"source":["# Lecture Lab"]},{"cell_type":"markdown","metadata":{"id":"53_v0QDNxW4p"},"source":["Today we're going to look at x and y arrays, something that we'll need for training our text classifiers later.\n","\n","Basically, for our dataset we have two essential pieces of information: First, the texts that we're working with. Second, the category that each text belongs to. We call our data that we use (texts) the *x array*. And we call the list of labels that each belongs to the *y array*. For example, in *scikit-learn* the convention is to talk about X and y. This just means the language and the labels!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxMpaZW0xW4q","executionInfo":{"status":"ok","timestamp":1615924969173,"user_tz":240,"elapsed":5800,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"61d42460-43b6-40a9-9741-f92572be254f"},"source":["from text_analytics import text_analytics\n","import os\n","import pandas as pd\n","\n","ai = text_analytics()\n","print(\"Done!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jdVfknplxW4r"},"source":["This time we're going to work with tweets that represent different cities around the world. So we first load this data into memory."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ll3-kGDOxW4s","executionInfo":{"status":"ok","timestamp":1615924991288,"user_tz":240,"elapsed":19002,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"67d7a6c5-733f-4ae4-cf55-7f192652fde7"},"source":["file = os.path.join(ai.data_dir, \"Twitter_by_City.gz\")\n","df = pd.read_csv(file, index_col = 0)\n","print(df)\n","print(\"Done!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["            City                                               Text\n","0       auckland   i m sorry who didn t vote beige show me these...\n","1       auckland   meet our analysts idc australia new zealand a...\n","2       auckland   aue my great grandfather was an aboriginal te...\n","3       auckland   yeah dumping corsica would be a good idea tot...\n","4       auckland   thank you for your partnership to help get de...\n","...          ...                                                ...\n","373123   toronto   will hopefully be great and all but this is j...\n","373124   toronto   leafs defenceman jake muzzin out for remainde...\n","373125   toronto   read into everything going on in lebanon not ...\n","373126   toronto   remy i hate this debate he s a street rat he ...\n","373127   toronto   brutal other day i lost the bucks first quart...\n","\n","[373128 rows x 2 columns]\n","Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tofQAFsaxW4v"},"source":["Ok, so now we have our data. Instead of a full table or dataframe like this, we want to separate arrays."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwZEmJ4NxW4v","executionInfo":{"status":"ok","timestamp":1615925007766,"user_tz":240,"elapsed":246,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"8473b451-4db8-41b9-8b38-ceceea1f8de8"},"source":["x = df.loc[:,\"Text\"]\n","y = df.loc[:,\"City\"]\n","print(\"Done!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZPn7cjRVxW4w"},"source":["So, later, when we use *scikit-learn* or *tensorflow* to build models, we can use this syntax to get our respective x and y arrays. Let's see what they look like."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQ7D1UZdxW4w","executionInfo":{"status":"ok","timestamp":1615925015380,"user_tz":240,"elapsed":262,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"7085b4fa-35b0-4f93-c543-ee0513fd118d"},"source":["print(x)\n","print(y)\n","print(\"Done!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0          i m sorry who didn t vote beige show me these...\n","1          meet our analysts idc australia new zealand a...\n","2          aue my great grandfather was an aboriginal te...\n","3          yeah dumping corsica would be a good idea tot...\n","4          thank you for your partnership to help get de...\n","                                ...                        \n","373123     will hopefully be great and all but this is j...\n","373124     leafs defenceman jake muzzin out for remainde...\n","373125     read into everything going on in lebanon not ...\n","373126     remy i hate this debate he s a street rat he ...\n","373127     brutal other day i lost the bucks first quart...\n","Name: Text, Length: 373128, dtype: object\n","0         auckland\n","1         auckland\n","2         auckland\n","3         auckland\n","4         auckland\n","            ...   \n","373123     toronto\n","373124     toronto\n","373125     toronto\n","373126     toronto\n","373127     toronto\n","Name: City, Length: 373128, dtype: object\n","Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WMMcuhS8xW4w"},"source":["You'll notice that each array is the same length: 373,128 items. Each item here is actually an aggregation of about 25 tweets. That gives us more data per sample, which is a lot easier to work with.\n","\n","And that's all for today! Here we've learned how to make separate arrays that represent our data and our meta-data.\n","\n","Try to use the code block below to x and y arrays for a new data set, this time using \"Author\" as the label:\n","\n","    \"Gutenberg.1850.Authors.gz\""]},{"cell_type":"code","metadata":{"id":"zhM9Q4GPxW4w"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UtbyQTCyo6FE"},"source":["# Practice"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZUxRBLro73B","executionInfo":{"status":"ok","timestamp":1615925495300,"user_tz":240,"elapsed":7602,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"c474bfff-0aeb-41f3-ea8e-a033114e0c82"},"source":["file = os.path.join(ai.data_dir, \"Gutenberg.1850.Authors.gz\")\r\n","df = pd.read_csv(file, index_col = 0)\r\n","\r\n","# Pandas formating \r\n","# inclears number of columns to display in line and column with for easier reading \r\n","pd.set_option(\"display.max_columns\", 10)\r\n","pd.set_option('display.width', 1000)\r\n","\r\n","print(df)\r\n","print(\"Done!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["        index  Generation    Author                Title                                               Text\n","0         150        1850  abbott_j  alexander_the_great  note project gutenberg also has an html versio...\n","1         151        1850  abbott_j  alexander_the_great  it will be recollected to epirus where her fri...\n","2         152        1850  abbott_j  alexander_the_great  it would be best to endeavor to effect a landi...\n","3         153        1850  abbott_j  alexander_the_great  transport his army across the straits the army...\n","4         154        1850  abbott_j  alexander_the_great  that the true greatness of the soul of alexand...\n","...       ...         ...       ...                  ...                                                ...\n","17042  125483        1850    wood_h       victor_serenus  since i have been with amabel it hath waxed st...\n","17043  125484        1850    wood_h       victor_serenus  his face uttered a loud cry and shrank back af...\n","17044  125485        1850    wood_h       victor_serenus  the taurus mountains made the afternoon balmy ...\n","17045  125486        1850    wood_h       victor_serenus  me to a place not very far distant where all m...\n","17046  125487        1850    wood_h       victor_serenus  never knew these things before now thou dost r...\n","\n","[15999 rows x 5 columns]\n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67uJDmAqpGRB","executionInfo":{"status":"ok","timestamp":1615925416744,"user_tz":240,"elapsed":298,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"12a04a53-0c3b-41ab-aa21-fc74bc535558"},"source":["x = df.loc[:,\"Text\"]\r\n","y = df.loc[:,\"Author\"]\r\n","\r\n","print(\"Text, X\")\r\n","print(\"\")\r\n","print(x)\r\n","print(\"\")\r\n","print(\"Labels, Y\")\r\n","print(\"\")\r\n","print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Text, X\n","\n","0        note project gutenberg also has an html versio...\n","1        it will be recollected to epirus where her fri...\n","2        it would be best to endeavor to effect a landi...\n","3        transport his army across the straits the army...\n","4        that the true greatness of the soul of alexand...\n","                               ...                        \n","17042    since i have been with amabel it hath waxed st...\n","17043    his face uttered a loud cry and shrank back af...\n","17044    the taurus mountains made the afternoon balmy ...\n","17045    me to a place not very far distant where all m...\n","17046    never knew these things before now thou dost r...\n","Name: Text, Length: 15999, dtype: object\n","\n","Labels, Y\n","\n","0        abbott_j\n","1        abbott_j\n","2        abbott_j\n","3        abbott_j\n","4        abbott_j\n","           ...   \n","17042      wood_h\n","17043      wood_h\n","17044      wood_h\n","17045      wood_h\n","17046      wood_h\n","Name: Author, Length: 15999, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xwkWb4xpwl6","executionInfo":{"status":"ok","timestamp":1615925604998,"user_tz":240,"elapsed":297,"user":{"displayName":"Albin Bajramovic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgshKWHetShBZgENx5NdgQVbr3hhhfpUjI4Z7AK=s64","userId":"01478343695782867773"}},"outputId":"7c7b9dc2-7b8a-4cb0-e2e9-23a155e29e9c"},"source":["x.loc[[1]]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    it will be recollected to epirus where her fri...\n","Name: Text, dtype: object"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"vVeSa9iQqW_x"},"source":[""],"execution_count":null,"outputs":[]}]}